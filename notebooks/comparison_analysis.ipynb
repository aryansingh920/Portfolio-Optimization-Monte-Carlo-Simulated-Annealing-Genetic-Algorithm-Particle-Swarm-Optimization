{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Optimization Comparative Analysis\n",
    "\n",
    "This notebook provides a detailed comparison of different portfolio optimization techniques:\n",
    "- Monte Carlo Simulation\n",
    "- Simulated Annealing\n",
    "- Genetic Algorithm\n",
    "- Particle Swarm Optimization\n",
    "\n",
    "We'll analyze their performance, efficiency, and practical implications for portfolio management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import project modules\n",
    "from data.data_loader import DataLoader\n",
    "from optimizers.monte_carlo import MonteCarloOptimizer\n",
    "from optimizers.simulated_annealing import SimulatedAnnealingOptimizer\n",
    "from optimizers.genetic_algorithm import GeneticAlgorithmOptimizer\n",
    "from optimizers.particle_swarm import ParticleSwarmOptimizer\n",
    "from utils.metrics import PortfolioMetrics\n",
    "from utils.visualization import PortfolioVisualizer\n",
    "from config.config import CONFIG\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection and Preprocessing\n",
    "\n",
    "First, we'll load historical price data for our selected assets and prepare it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "data_loader = DataLoader()\n",
    "\n",
    "# Define stock universe\n",
    "tickers = CONFIG.default_tickers\n",
    "\n",
    "# Load price data\n",
    "price_data = data_loader.load_data(tickers, period='5y')\n",
    "\n",
    "# Calculate returns\n",
    "returns_data = data_loader.calculate_returns()\n",
    "\n",
    "# Get market data for comparison\n",
    "market_returns, risk_free_rate = data_loader.get_market_data()\n",
    "\n",
    "print(f\"Dataset Summary:\")\n",
    "print(f\"Number of assets: {len(tickers)}\")\n",
    "print(f\"Date range: {returns_data.index[0]} to {returns_data.index[-1]}\")\n",
    "print(f\"Number of trading days: {len(returns_data)}\")\n",
    "print(f\"Risk-free rate: {risk_free_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate basic statistics\n",
    "annual_factor = 252  # Trading days in a year\n",
    "stats = pd.DataFrame({\n",
    "    'Annual Return': returns_data.mean() * annual_factor,\n",
    "    'Annual Volatility': returns_data.std() * np.sqrt(annual_factor),\n",
    "    'Sharpe Ratio': (returns_data.mean() * annual_factor - risk_free_rate) / \n",
    "                    (returns_data.std() * np.sqrt(annual_factor)),\n",
    "    'Skewness': returns_data.skew(),\n",
    "    'Kurtosis': returns_data.kurtosis()\n",
    "})\n",
    "\n",
    "display(stats.style.format('{:.2%}').background_gradient(cmap='RdYlGn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize return distributions\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Returns distribution\n",
    "for ticker in tickers:\n",
    "    sns.kdeplot(data=returns_data[ticker], ax=axes[0], label=ticker)\n",
    "axes[0].set_title('Return Distributions')\n",
    "axes[0].set_xlabel('Daily Return')\n",
    "axes[0].legend()\n",
    "\n",
    "# Cumulative returns\n",
    "cumulative_returns = (1 + returns_data).cumprod()\n",
    "cumulative_returns.plot(ax=axes[1])\n",
    "axes[1].set_title('Cumulative Returns')\n",
    "axes[1].set_ylabel('Growth of $1')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and visualize correlation matrix\n",
    "correlation_matrix = returns_data.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            annot=True, \n",
    "            cmap='RdYlBu', \n",
    "            center=0, \n",
    "            fmt='.2f')\n",
    "plt.title('Asset Correlation Matrix')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Portfolio Optimization\n",
    "\n",
    "Now we'll implement and compare different optimization approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimizer(optimizer_class, returns_data, risk_free_rate, **kwargs):\n",
    "    \"\"\"Run optimization and return results.\"\"\"\n",
    "    optimizer = optimizer_class(returns_data, risk_free_rate)\n",
    "    weights, metrics = optimizer.optimize(**kwargs)\n",
    "    \n",
    "    results = {\n",
    "        'weights': pd.Series(weights, index=returns_data.columns),\n",
    "        'metrics': metrics\n",
    "    }\n",
    "    \n",
    "    if hasattr(optimizer, 'get_optimization_history'):\n",
    "        results['history'] = optimizer.get_optimization_history()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Dictionary to store results\n",
    "optimization_results = {}\n",
    "\n",
    "# Run Monte Carlo optimization\n",
    "optimization_results['Monte Carlo'] = run_optimizer(\n",
    "    MonteCarloOptimizer,\n",
    "    returns_data,\n",
    "    risk_free_rate,\n",
    "    n_portfolios=10000\n",
    ")\n",
    "\n",
    "# Run Simulated Annealing optimization\n",
    "optimization_results['Simulated Annealing'] = run_optimizer(\n",
    "    SimulatedAnnealingOptimizer,\n",
    "    returns_data,\n",
    "    risk_free_rate,\n",
    "    max_iterations=1000\n",
    ")\n",
    "\n",
    "# Run Genetic Algorithm optimization\n",
    "optimization_results['Genetic Algorithm'] = run_optimizer(\n",
    "    GeneticAlgorithmOptimizer,\n",
    "    returns_data,\n",
    "    risk_free_rate,\n",
    "    n_generations=100\n",
    ")\n",
    "\n",
    "# Run Particle Swarm optimization\n",
    "optimization_results['Particle Swarm'] = run_optimizer(\n",
    "    ParticleSwarmOptimizer,\n",
    "    returns_data,\n",
    "    risk_free_rate,\n",
    "    n_iterations=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Compare Optimal Portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison of portfolio weights\n",
    "weights_comparison = pd.DataFrame({\n",
    "    name: results['weights']\n",
    "    for name, results in optimization_results.items()\n",
    "})\n",
    "\n",
    "# Plot weight comparison\n",
    "ax = weights_comparison.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Portfolio Weights by Optimization Method')\n",
    "plt.xlabel('Asset')\n",
    "plt.ylabel('Weight')\n",
    "plt.legend(title='Method')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display metrics comparison\n",
    "metrics_comparison = pd.DataFrame({\n",
    "    name: results['metrics']\n",
    "    for name, results in optimization_results.items()\n",
    "}).T\n",
    "\n",
    "display(metrics_comparison.style\n",
    "       .format('{:.4f}')\n",
    "       .background_gradient(cmap='RdYlGn'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Convergence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convergence for algorithms with history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (name, results) in enumerate(optimization_results.items()):\n",
    "    if 'history' in results:\n",
    "        history = results['history']\n",
    "        if 'best_fitness' in history.columns:\n",
    "            history['best_fitness'].plot(ax=axes[idx],\n",
    "                                        label='Best Fitness')\n",
    "        if 'avg_fitness' in history.columns:\n",
    "            history['avg_fitness'].plot(ax=axes[idx],\n",
    "                                       label='Average Fitness',\n",
    "                                       alpha=0.7)\n",
    "        axes[idx].set_title(f'{name} Convergence')\n",
    "        axes[idx].set_xlabel('Iteration')\n",
    "        axes[idx].set_ylabel('Fitness Value')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(True)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Risk Analysis of Optimal Portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate portfolio returns for each optimization method\n",
    "portfolio_returns = {}\n",
    "for name, results in optimization_results.items():\n",
    "    weights = results['weights']\n",
    "    portfolio_returns[name] = returns_data.dot(weights)\n",
    "\n",
    "portfolio_returns = pd.DataFrame(portfolio_returns)\n",
    "\n",
    "# Calculate cumulative returns\n",
    "cumulative_returns = (1 + portfolio_returns).cumprod()\n",
    "\n",
    "# Plot cumulative returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "cumulative_returns.plot()\n",
    "plt.title('Cumulative Returns of Optimized Portfolios')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Growth of $1')\n",
    "plt.grid(True)\n",
    "plt.legend(title='Optimization Method')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling metrics\n",
    "window = 252  # One year rolling window\n",
    "\n",
    "rolling_vol = portfolio_returns.rolling(window).std() * np.sqrt(252)\n",
    "rolling_sharpe = (portfolio_returns.rolling(window).mean() * 252 - risk_free_rate) / (portfolio_returns.rolling(window).std() * np.sqrt(252))\n",
    "\n",
    "# Plot rolling metrics\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "rolling_vol.plot(ax=axes[0])\n",
    "axes[0].set_title('Rolling Annual Volatility')\n",
    "axes[0].set_ylabel('Volatility')\n",
    "axes[0].grid(True)\n",
    "\n",
    "rolling_sharpe.plot(ax=axes[1])\n",
    "axes[1].set_title('Rolling Sharpe Ratio')\n",
    "axes[1].set_ylabel('Sharpe Ratio')\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance Analysis and Risk Metrics\n",
    "\n",
    "Let's analyze the risk-adjusted performance metrics for each optimization method in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate comprehensive performance metrics for each portfolio\n",
    "performance_metrics = {}\n",
    "\n",
    "for name, returns in portfolio_returns.items():\n",
    "    # Calculate drawdowns\n",
    "    cum_returns = (1 + returns).cumprod()\n",
    "    rolling_max = cum_returns.expanding().max()\n",
    "    drawdowns = (cum_returns - rolling_max) / rolling_max\n",
    "    \n",
    "    # Calculate various metrics\n",
    "    annual_return = returns.mean() * 252\n",
    "    annual_vol = returns.std() * np.sqrt(252)\n",
    "    sharpe = (annual_return - risk_free_rate) / annual_vol\n",
    "    \n",
    "    # Sortino Ratio\n",
    "    downside_returns = returns[returns < 0]\n",
    "    downside_vol = downside_returns.std() * np.sqrt(252)\n",
    "    sortino = (annual_return - risk_free_rate) / downside_vol\n",
    "    \n",
    "    # Maximum Drawdown\n",
    "    max_drawdown = drawdowns.min()\n",
    "    \n",
    "    # Value at Risk (95%)\n",
    "    var_95 = np.percentile(returns, 5)\n",
    "    \n",
    "    # Conditional VaR (Expected Shortfall)\n",
    "    cvar_95 = returns[returns <= var_95].mean()\n",
    "    \n",
    "    performance_metrics[name] = {\n",
    "        'Annual Return': annual_return,\n",
    "        'Annual Volatility': annual_vol,\n",
    "        'Sharpe Ratio': sharpe,\n",
    "        'Sortino Ratio': sortino,\n",
    "        'Maximum Drawdown': max_drawdown,\n",
    "        'VaR (95%)': var_95,\n",
    "        'CVaR (95%)': cvar_95\n",
    "    }\n",
    "\n",
    "# Convert to DataFrame\n",
    "performance_df = pd.DataFrame(performance_metrics).T\n",
    "\n",
    "# Display formatted results\n",
    "display(performance_df.style\n",
    "        .format({\n",
    "            'Annual Return': '{:.2%}',\n",
    "            'Annual Volatility': '{:.2%}',\n",
    "            'Sharpe Ratio': '{:.2f}',\n",
    "            'Sortino Ratio': '{:.2f}',\n",
    "            'Maximum Drawdown': '{:.2%}',\n",
    "            'VaR (95%)': '{:.2%}',\n",
    "            'CVaR (95%)': '{:.2%}'\n",
    "        })\n",
    "        .background_gradient(cmap='RdYlGn'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Risk Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot return distributions\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Return distributions\n",
    "for name in portfolio_returns.columns:\n",
    "    sns.kdeplot(data=portfolio_returns[name], ax=ax1, label=name)\n",
    "ax1.set_title('Return Distributions')\n",
    "ax1.set_xlabel('Daily Return')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.legend(title='Method')\n",
    "\n",
    "# QQ plot for normality check\n",
    "from scipy import stats\n",
    "for name in portfolio_returns.columns:\n",
    "    returns = portfolio_returns[name]\n",
    "    qq = stats.probplot(returns, dist='norm')\n",
    "    ax2.plot(qq[0][0], qq[0][1], label=name)\n",
    "\n",
    "ax2.set_title('Q-Q Plot vs Normal Distribution')\n",
    "ax2.set_xlabel('Theoretical Quantiles')\n",
    "ax2.set_ylabel('Sample Quantiles')\n",
    "ax2.legend(title='Method')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Drawdown Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate drawdowns for each portfolio\n",
    "drawdowns = pd.DataFrame()\n",
    "\n",
    "for name in portfolio_returns.columns:\n",
    "    cum_returns = (1 + portfolio_returns[name]).cumprod()\n",
    "    rolling_max = cum_returns.expanding().max()\n",
    "    drawdowns[name] = (cum_returns - rolling_max) / rolling_max\n",
    "\n",
    "# Plot drawdowns\n",
    "plt.figure(figsize=(12, 6))\n",
    "drawdowns.plot()\n",
    "plt.title('Portfolio Drawdowns')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Drawdown')\n",
    "plt.grid(True)\n",
    "plt.legend(title='Method')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparative Analysis and Conclusions\n",
    "\n",
    "Let's summarize the key findings from our analysis of different optimization methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "summary = pd.DataFrame(index=optimization_results.keys())\n",
    "\n",
    "# Add key metrics\n",
    "summary['Portfolio Diversification'] = [len(results['weights'][results['weights'] > 0.01]) \n",
    "                                       for results in optimization_results.values()]\n",
    "summary['Max Asset Weight'] = [results['weights'].max() \n",
    "                              for results in optimization_results.values()]\n",
    "summary['Sharpe Ratio'] = [results['metrics']['sharpe_ratio'] \n",
    "                          for results in optimization_results.values()]\n",
    "summary['Annual Return'] = performance_df['Annual Return']\n",
    "summary['Annual Risk'] = performance_df['Annual Volatility']\n",
    "\n",
    "display(summary.style\n",
    "        .format({\n",
    "            'Max Asset Weight': '{:.2%}',\n",
    "            'Sharpe Ratio': '{:.2f}',\n",
    "            'Annual Return': '{:.2%}',\n",
    "            'Annual Risk': '{:.2%}'\n",
    "        })\n",
    "        .background_gradient(cmap='RdYlGn'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings:\n",
    "\n",
    "1. **Optimization Effectiveness**\n",
    "   - Compare Sharpe ratios and risk-adjusted returns across methods\n",
    "   - Analyze the trade-off between return and risk for each approach\n",
    "\n",
    "2. **Portfolio Characteristics**\n",
    "   - Evaluate diversification levels achieved by each method\n",
    "   - Compare concentration risk and maximum position sizes\n",
    "\n",
    "3. **Risk Management**\n",
    "   - Assess downside protection capabilities\n",
    "   - Compare drawdown characteristics\n",
    "\n",
    "4. **Implementation Considerations**\n",
    "   - Discuss computational efficiency\n",
    "   - Consider stability of solutions\n",
    "   - Evaluate practical implementation challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Out-of-Sample Testing\n",
    "\n",
    "Let's evaluate how these portfolios would have performed in a different time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test period data\n",
    "test_data = data_loader.load_data(tickers, period='1y')\n",
    "test_returns = data_loader.calculate_returns()\n",
    "\n",
    "# Calculate out-of-sample portfolio returns\n",
    "oos_returns = pd.DataFrame()\n",
    "for name, results in optimization_results.items():\n",
    "    weights = results['weights']\n",
    "    oos_returns[name] = test_returns.dot(weights)\n",
    "\n",
    "# Calculate cumulative returns\n",
    "oos_cumulative = (1 + oos_returns).cumprod()\n",
    "\n",
    "# Plot out-of-sample performance\n",
    "plt.figure(figsize=(12, 6))\n",
    "oos_cumulative.plot()\n",
    "plt.title('Out-of-Sample Portfolio Performance')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Growth of $1')\n",
    "plt.grid(True)\n",
    "plt.legend(title='Method')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
